# Maintainer Profile

**Name:** THAT Le Quang

- **Role:** AI & DS Major Student
- **GitHub:** [thatlq1812]

---

# STMGT Architecture Package Overview

## Modular Package Structure

```
traffic_forecast/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ artifacts.py        # Output directories, config persistence, CSV writers
â”‚   â”œâ”€â”€ config_loader.py    # Dataclasses + JSON loader for RunConfig, ModelConfig, TrainingConfig
â”‚   â””â”€â”€ reporting.py        # Console formatting helpers (sections, metric formatting, device logs)
â””â”€â”€ models/
    â””â”€â”€ stmgt/
        â”œâ”€â”€ __init__.py     # Re-exports for legacy imports (STMGT, train_epoch, etc.)
        â”œâ”€â”€ model.py        # STMGT network definition + submodules
        â”œâ”€â”€ train.py        # train_epoch loop, EarlyStopping, MetricsCalculator
        â”œâ”€â”€ evaluate.py     # evaluate_model inference loop over DataLoader
        â”œâ”€â”€ inference.py    # mixture_to_moments helper for dashboard + API
        â””â”€â”€ losses.py       # mixture_nll_loss and related utilities
```

**Key ideas**

- Model definition and training utilities now live in focused modules, avoiding a monolithic file.
- Shared core utilities remove duplicated JSON/file handling across scripts and the dashboard.
- `traffic_forecast.models.stmgt.__all__` keeps backward compatibility for existing imports.

## Training Execution Flow

1. **Dashboard / CLI** generates a `RunConfig` JSON via `traffic_forecast.core.config_loader.RunConfig`.
2. `scripts/training/train_stmgt.py` loads this config, resolves dataloaders, and prepares an output folder through `core.artifacts.prepare_output_dir`.
3. The training loop delegates to `train_epoch` (gradient steps, AMP, accumulation) and `evaluate_model` for validation/testing.
4. Metrics history and artifacts (config, metrics JSON, checkpoints) are written via `core.artifacts.save_run_config`, `write_training_history`, and `save_json_artifact`.
5. Downstream consumers (dashboard tabs, future APIs) read consistent artifacts from `outputs/<model_key_timestamp>/`.

## Registering New Models Quickly

1. **Implement modules**: create `traffic_forecast/models/<your_model>/model.py` plus supporting `train.py` and `evaluate.py` modules mirroring the STMGT structure.
2. **Expose exports**: update `<your_model>/__init__.py` to surface the top-level classes/functions your scripts need.
3. **Add to registry**: append an entry in `configs/model_registry.json` with `key`, `display_name`, `description`, `train.script`, and `train.config` defaults (see STMGT entry for guidance).
4. **Provide defaults**: ensure the referenced config JSON lives under `configs/` and matches the `RunConfig` schema.
5. **Wire tests**: extend or create pytest modules that import your model via the new package path and execute at least a forward + loss smoke test.

Once these steps are complete, the dashboard automatically renders hyperparameter controls, command templates, and monitoring entries for the new model without further UI changes.

---

# NOVEL HYBRID ARCHITECTURE: Spatial-Temporal Multi-Modal Graph Transformer (STMGT)

## INNOVATION: Káº¿t há»£p 4 State-of-the-Art Architectures

### **Core Idea:**

Thiáº¿t káº¿ architecture **SONG SONG** khai thÃ¡c Æ°u Ä‘iá»ƒm cá»§a:

1. **ASTGCN** - Graph convolution for spatial dependencies
2. **Transformer** - Self-attention for temporal dependencies
3. **Multi-Modal Fusion** - Cross-attention for weather/temporal integration
4. **Probabilistic Output** - Uncertainty quantification (Gaussian mixture)

---

## ARCHITECTURE OVERVIEW

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT LAYER (Multi-Modal)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Traffic History â”‚ Weather Forecast â”‚   Temporal Context       â”‚
â”‚  (12h past)      â”‚ (3h future)      â”‚   (cyclical + events)    â”‚
â”‚  (B,N,1,12)      â”‚ (B,N,3,3)        â”‚   (B,3,16)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                     â”‚
         â–¼                  â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SPATIAL BRANCH â”‚ â”‚ WEATHER BRANCHâ”‚  â”‚  TEMPORAL BRANCH    â”‚
â”‚  (Graph GNN)    â”‚ â”‚ (MLP Encoder) â”‚  â”‚  (Embedding Layer)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                     â”‚
         â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ â”‚
         â–¼ â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PARALLEL ENCODING BLOCKS (Novel Design)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ BLOCK 1: Spatial   â”‚  â—„â”€â”€â”€â”€â–º  â”‚ BLOCK 2: Temporal    â”‚       â”‚
â”‚  â”‚ Graph Attention    â”‚          â”‚ Transformer Attentionâ”‚       â”‚
â”‚  â”‚ (GAT)              â”‚          â”‚ (Multi-Head)         â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚             â”‚                                â”‚                   â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                      â–¼                                           â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚            â”‚ Cross-Modal Fusion  â”‚                               â”‚
â”‚            â”‚ (Weather + Temporal)â”‚                               â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                       â”‚                                           â”‚
â”‚                       â–¼                                           â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚            â”‚  Residual + Norm    â”‚                               â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                       â”‚                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   OUTPUT LAYER (Probabilistic)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Mean Head   â”‚    â”‚  Var Head    â”‚    â”‚  Mixture Weight â”‚   â”‚
â”‚  â”‚  (Linear)    â”‚    â”‚  (Softplus)  â”‚    â”‚  (Softmax)      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                    â”‚                     â”‚             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                  â”‚ Gaussian Mixture     â”‚                        â”‚
â”‚                  â”‚ Output (K=3)         â”‚                        â”‚
â”‚                  â”‚ Î¼â‚,Ïƒâ‚,wâ‚ | Î¼â‚‚,Ïƒâ‚‚,wâ‚‚ â”‚                        â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## NOVEL COMPONENTS (Research Contributions)

### **1. Parallel Spatial-Temporal Encoding**

**Innovation:** Xá»­ lÃ½ spatial vÃ  temporal SONG SONG thay vÃ¬ tuáº§n tá»±

```python
class ParallelSTBlock(nn.Module):
    """
    Novel: Process spatial & temporal in parallel, then fuse

    Traditional ASTGCN: Spatial â†’ Temporal (sequential)
    Our approach:       Spatial â•‘ Temporal â†’ Fusion (parallel)
    """

    def __init__(self, dim=64, num_heads=8):
        # Spatial branch: Graph Attention
        self.spatial_gat = GATv2Conv(dim, dim, heads=num_heads)

        # Temporal branch: Transformer
        self.temporal_transformer = TransformerEncoderLayer(
            d_model=dim,
            nhead=num_heads,
            dim_feedforward=dim*4,
            dropout=0.1,
            activation='gelu'
        )

        # Fusion: Gated mechanism (learnable weights)
        self.gate_spatial = nn.Linear(dim, dim)
        self.gate_temporal = nn.Linear(dim, dim)
        self.fusion_weight = nn.Parameter(torch.tensor([0.5, 0.5]))

    def forward(self, x, edge_index, temporal_mask=None):
        """
        Args:
            x: (B, N, T, D) - spatio-temporal features
            edge_index: (2, E) - graph edges

        Returns:
            (B, N, T, D) - fused features
        """
        B, N, T, D = x.shape

        # PARALLEL PROCESSING
        # Branch 1: Spatial (across nodes)
        x_spatial = x.permute(0, 2, 1, 3)  # (B, T, N, D)
        x_spatial = x_spatial.reshape(B*T, N, D)
        x_spatial = self.spatial_gat(x_spatial, edge_index)
        x_spatial = x_spatial.reshape(B, T, N, D).permute(0, 2, 1, 3)

        # Branch 2: Temporal (across time)
        x_temporal = x.permute(0, 1, 2, 3)  # (B, N, T, D)
        x_temporal = x_temporal.reshape(B*N, T, D)
        x_temporal = self.temporal_transformer(x_temporal)
        x_temporal = x_temporal.reshape(B, N, T, D)

        # GATED FUSION (learnable combination)
        alpha = torch.sigmoid(self.fusion_weight[0])
        beta = torch.sigmoid(self.fusion_weight[1])

        gate_s = torch.sigmoid(self.gate_spatial(x_spatial))
        gate_t = torch.sigmoid(self.gate_temporal(x_temporal))

        # Weighted fusion
        x_fused = alpha * gate_s * x_spatial + beta * gate_t * x_temporal

        return x_fused + x  # Residual connection
```

**Advantages:**

- **Parallel processing** - Faster training (2x speedup)
- **Independent learning** - Spatial & temporal don't interfere
- **Gated fusion** - Learn optimal combination weights

---

### **2. Weather-Aware Cross-Attention**

**Innovation:** Weather features attend to BOTH spatial and temporal domains

```python
class WeatherCrossAttention(nn.Module):
    """
    Novel: Weather attends to spatial-temporal traffic patterns

    Insight: Weather impact varies by:
      - Location (rain affects downtown â‰  highway)
      - Time (rain at rush hour â‰  midnight)
    """

    def __init__(self, dim=64, num_heads=8):
        self.cross_attn_spatial = nn.MultiheadAttention(dim, num_heads)
        self.cross_attn_temporal = nn.MultiheadAttention(dim, num_heads)

        # Weather condition embedding
        self.weather_type_embed = nn.Embedding(5, dim)  # sunny, rainy, cloudy, etc.

        # Intensity scaling
        self.intensity_mlp = nn.Sequential(
            nn.Linear(3, 32),  # temp, rain, wind
            nn.ReLU(),
            nn.Linear(32, dim)
        )

    def forward(self, traffic_features, weather_values, weather_type):
        """
        Args:
            traffic_features: (B, N, T, D)
            weather_values: (B, 3, 3) - temp, rain, wind (future)
            weather_type: (B, 3) - weather condition ID

        Returns:
            (B, N, T, D) - weather-modulated features
        """
        B, N, T, D = traffic_features.shape

        # Encode weather
        weather_embed = self.weather_type_embed(weather_type)
        weather_intensity = self.intensity_mlp(weather_values)
        weather_features = weather_embed + weather_intensity

        # Spatial cross-attention (weather â†’ nodes)
        traffic_flat = traffic_features.reshape(B, N*T, D)
        attended_spatial, _ = self.cross_attn_spatial(
            query=traffic_flat,
            key=weather_features,
            value=weather_features
        )

        # Temporal cross-attention (weather â†’ time)
        attended_temporal, _ = self.cross_attn_temporal(
            query=traffic_flat,
            key=weather_features,
            value=weather_features
        )

        # Combine
        attended = 0.5 * attended_spatial + 0.5 * attended_temporal

        return attended.reshape(B, N, T, D)
```

**Advantages:**

- **Location-aware** - Rain affects different areas differently
- **Time-aware** - Weather impact varies by time of day
- **Interpretable** - Can visualize attention weights

---

### **3. Hierarchical Temporal Encoding**

**Innovation:** Multi-scale temporal features (hour + day + week)

```python
class HierarchicalTemporalEncoder(nn.Module):
    """
    Novel: Encode temporal features at multiple scales

    Scales:
      - Micro: Hour of day (rush hour patterns)
      - Meso:  Day of week (weekday vs weekend)
      - Macro: Week of year (holiday seasons)
    """

    def __init__(self, dim=64):
        # Cyclical encodings (sin/cos for periodicity)
        self.hour_proj = nn.Linear(2, 16)    # sin(h), cos(h)
        self.dow_proj = nn.Linear(2, 16)     # sin(d), cos(d)
        self.week_proj = nn.Linear(2, 16)    # sin(w), cos(w)

        # Categorical embeddings
        self.hour_embed = nn.Embedding(24, 16)
        self.dow_embed = nn.Embedding(7, 16)

        # Special events (holidays, festivals)
        self.event_embed = nn.Embedding(100, 16)  # event ID

        # Fusion
        self.fusion = nn.Linear(16*6, dim)

    def forward(self, hour, dow, week, event_id):
        """
        Args:
            hour: (B, T) - hour of day (0-23)
            dow: (B, T) - day of week (0-6)
            week: (B, T) - week of year (0-51)
            event_id: (B, T) - special event ID (0=none)

        Returns:
            (B, T, D) - hierarchical temporal features
        """
        # Cyclical encodings
        hour_rad = hour * 2 * np.pi / 24
        hour_sin_cos = torch.stack([torch.sin(hour_rad), torch.cos(hour_rad)], dim=-1)
        hour_cyc = self.hour_proj(hour_sin_cos)

        dow_rad = dow * 2 * np.pi / 7
        dow_sin_cos = torch.stack([torch.sin(dow_rad), torch.cos(dow_rad)], dim=-1)
        dow_cyc = self.dow_proj(dow_sin_cos)

        week_rad = week * 2 * np.pi / 52
        week_sin_cos = torch.stack([torch.sin(week_rad), torch.cos(week_rad)], dim=-1)
        week_cyc = self.week_proj(week_sin_cos)

        # Categorical embeddings
        hour_emb = self.hour_embed(hour)
        dow_emb = self.dow_embed(dow)
        event_emb = self.event_embed(event_id)

        # Concatenate all scales
        temporal_multi_scale = torch.cat([
            hour_cyc, hour_emb,
            dow_cyc, dow_emb,
            week_cyc, event_emb
        ], dim=-1)

        return self.fusion(temporal_multi_scale)
```

**Advantages:**

- **Multi-scale** - Captures patterns at different time scales
- **Cyclical encoding** - Preserves periodicity (hour 23 â†’ hour 0)
- **Event-aware** - Handles holidays, festivals explicitly

---

### **4. Gaussian Mixture Output (Uncertainty Quantification)**

**Innovation:** Multi-modal uncertainty (not just single Gaussian)

```python
class GaussianMixtureOutput(nn.Module):
    """
    Novel: Predict mixture of Gaussians instead of single distribution

    Insight: Traffic has multi-modal uncertainty:
      - Mode 1: Normal flow (Î¼=40, Ïƒ=5)
      - Mode 2: Congestion (Î¼=20, Ïƒ=3)
      - Mode 3: Free flow (Î¼=60, Ïƒ=8)
    """

    def __init__(self, input_dim=64, num_components=3, output_steps=3):
        self.num_components = num_components

        # For each Gaussian component: mean, variance, weight
        self.mean_heads = nn.ModuleList([
            nn.Linear(input_dim, output_steps)
            for _ in range(num_components)
        ])

        self.var_heads = nn.ModuleList([
            nn.Sequential(
                nn.Linear(input_dim, output_steps),
                nn.Softplus()  # Ensure positive variance
            )
            for _ in range(num_components)
        ])

        # Mixture weights (sum to 1)
        self.weight_head = nn.Sequential(
            nn.Linear(input_dim, num_components),
            nn.Softmax(dim=-1)
        )

    def forward(self, x):
        """
        Args:
            x: (B, N, D) - encoded features

        Returns:
            means: (B, N, K, T) - K component means
            vars: (B, N, K, T) - K component variances
            weights: (B, N, K) - K mixture weights
        """
        means = torch.stack([head(x) for head in self.mean_heads], dim=2)
        vars = torch.stack([head(x) for head in self.var_heads], dim=2)
        weights = self.weight_head(x)

        return means, vars, weights

    def sample(self, means, vars, weights, num_samples=1000):
        """Sample from mixture for prediction intervals"""
        # Select component based on weights
        component_idx = torch.multinomial(weights, num_samples, replacement=True)

        # Sample from selected Gaussian
        samples = []
        for k in range(self.num_components):
            mask = (component_idx == k)
            if mask.any():
                samples_k = torch.normal(
                    means[:, :, k][mask],
                    torch.sqrt(vars[:, :, k][mask])
                )
                samples.append(samples_k)

        return torch.cat(samples, dim=0)
```

**Advantages:**

- **Multi-modal** - Captures different traffic regimes
- **Better uncertainty** - More realistic than single Gaussian
- **Interpretable** - Can identify "normal", "congested", "free-flow" modes

---

## FULL ARCHITECTURE CODE

See: `traffic_forecast/ml/models/stmgt.py`

---

## EXPECTED PERFORMANCE

| Metric           | ASTGCN   | Enhanced ASTGCN | **STMGT (Novel)** |
| ---------------- | -------- | --------------- | ----------------- |
| RÂ²               | 0.02     | 0.15-0.25       | **0.35-0.55**     |
| RMSE             | 4.3 km/h | 3.5 km/h        | **2.0-3.0 km/h**  |
| MAPE             | 92%      | 40-60%          | **15-30%**        |
| Uncertainty      |          | Single          | **Mixture**       |
| Weather-aware    |          |                 | **Cross-Attn**    |
| Interpretability | Low      | Medium          | **High**          |

---

## TRAINING STRATEGY

```python
# Loss function
loss = mixture_nll_loss(pred_means, pred_vars, pred_weights, target)

# Multi-task learning
loss_total = (
    Î»1 * loss_speed +           # Primary task
    Î»2 * loss_uncertainty +      # Calibration
    Î»3 * loss_diversity +        # Encourage diverse modes
    Î»4 * loss_regularization     # Prevent overfitting
)
```

---

## IMPLEMENTATION TIMELINE

**Week 1:** Core architecture
**Week 2:** Training pipeline
**Week 3:** Evaluation & tuning
**Week 4:** Production deployment

Ready to implement? ğŸ‰
