{
  "seq_len": 12,
  "pred_len": 12,
  "batch_size": 32,
  "num_workers": 0,
  "learning_rate": 0.001,
  "weight_decay": 0.0001,
  "max_epochs": 100,
  "patience": 20,
  "drop_edge_p": 0.2,
  "num_components": 3,
  "hidden_dim": 64,
  "num_heads": 4,
  "num_layers": 2,
  "use_amp": true,
  "accumulation_steps": 1
}