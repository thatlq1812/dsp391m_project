{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a266e9eb",
   "metadata": {},
   "source": [
    "# Traffic Forecast ML Training Pipeline\n",
    "\n",
    "This notebook provides an end-to-end machine learning pipeline for traffic speed prediction.\n",
    "\n",
    "## Pipeline Steps:\n",
    "1. **Data Loading** - Load collected traffic data\n",
    "2. **Exploratory Data Analysis** - Understand data distribution\n",
    "3. **Feature Engineering** - Create temporal, spatial, weather features\n",
    "4. **Data Preprocessing** - Clean, scale, split data\n",
    "5. **Model Training** - Train multiple ML models\n",
    "6. **Model Evaluation** - Compare performance metrics\n",
    "7. **Feature Importance** - Identify key predictors\n",
    "8. **Model Persistence** - Save best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cf283f",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af24e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Pipeline imports\n",
    "from traffic_forecast.ml import (\n",
    "    DataLoader,\n",
    "    load_latest_data,\n",
    "    load_all_data,\n",
    "    DataPreprocessor,\n",
    "    split_data,\n",
    "    prepare_features_target,\n",
    "    build_features,\n",
    "    ModelTrainer,\n",
    "    compare_models\n",
    ")\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d946684",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96357fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DataLoader()\n",
    "\n",
    "# Check available runs\n",
    "print(\"Available data runs:\")\n",
    "runs = loader.list_runs()\n",
    "for i, run in enumerate(runs):\n",
    "    print(f\"  [{i}] {run['name']} - {run['timestamp']}\")\n",
    "\n",
    "# Get data summary\n",
    "summary = loader.get_data_summary()\n",
    "print(\"\\nData Summary:\")\n",
    "print(f\"  Total runs: {summary['total_runs']}\")\n",
    "if 'latest_run' in summary:\n",
    "    print(f\"  Latest run: {summary['latest_run']['name']}\")\n",
    "    print(f\"  Records: {summary['latest_run']['records']}\")\n",
    "    print(f\"  Features: {len(summary['latest_run']['features'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48454be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (choose one):\n",
    "\n",
    "# Option 1: Load latest run only\n",
    "df = loader.load_merged_data(run_idx=0)\n",
    "\n",
    "# Option 2: Load all runs\n",
    "# df = loader.load_multiple_runs()\n",
    "\n",
    "print(f\"Loaded {len(df)} records\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nData shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c41581",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b973cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "if len(missing) > 0:\n",
    "    print(missing)\n",
    "else:\n",
    "    print(\"No missing values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['speed_kmh'], bins=50, edgecolor='black')\n",
    "axes[0].set_title('Speed Distribution')\n",
    "axes[0].set_xlabel('Speed (km/h)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(df['speed_kmh'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[0].axvline(df['speed_kmh'].median(), color='green', linestyle='--', label='Median')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['speed_kmh'])\n",
    "axes[1].set_title('Speed Box Plot')\n",
    "axes[1].set_ylabel('Speed (km/h)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Speed Statistics:\")\n",
    "print(f\"  Mean: {df['speed_kmh'].mean():.2f} km/h\")\n",
    "print(f\"  Median: {df['speed_kmh'].median():.2f} km/h\")\n",
    "print(f\"  Std: {df['speed_kmh'].std():.2f} km/h\")\n",
    "print(f\"  Min: {df['speed_kmh'].min():.2f} km/h\")\n",
    "print(f\"  Max: {df['speed_kmh'].max():.2f} km/h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather vs Speed\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Temperature\n",
    "axes[0].scatter(df['temperature_c'], df['speed_kmh'], alpha=0.5)\n",
    "axes[0].set_title('Temperature vs Speed')\n",
    "axes[0].set_xlabel('Temperature (¬∞C)')\n",
    "axes[0].set_ylabel('Speed (km/h)')\n",
    "\n",
    "# Precipitation\n",
    "axes[1].scatter(df['precipitation_mm'], df['speed_kmh'], alpha=0.5)\n",
    "axes[1].set_title('Precipitation vs Speed')\n",
    "axes[1].set_xlabel('Precipitation (mm)')\n",
    "axes[1].set_ylabel('Speed (km/h)')\n",
    "\n",
    "# Wind\n",
    "axes[2].scatter(df['wind_speed_kmh'], df['speed_kmh'], alpha=0.5)\n",
    "axes[2].set_title('Wind vs Speed')\n",
    "axes[2].set_xlabel('Wind Speed (km/h)')\n",
    "axes[2].set_ylabel('Speed (km/h)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04c062",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d7474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build all features\n",
    "print(\"Building features...\")\n",
    "df_features = build_features(\n",
    "    df,\n",
    "    include_temporal=True,\n",
    "    include_spatial=True,\n",
    "    include_weather=True,\n",
    "    include_traffic=True,\n",
    "    include_lags=False,  # Set True if you have time series data\n",
    "    include_rolling=False  # Set True for rolling window features\n",
    ")\n",
    "\n",
    "print(f\"\\nFeatures created: {df_features.shape[1]} columns\")\n",
    "print(f\"New feature columns:\")\n",
    "new_cols = set(df_features.columns) - set(df.columns)\n",
    "print(f\"  {sorted(new_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temporal patterns\n",
    "if 'hour' in df_features.columns:\n",
    "    hourly_speed = df_features.groupby('hour')['speed_kmh'].mean()\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(hourly_speed.index, hourly_speed.values, marker='o')\n",
    "    plt.title('Average Speed by Hour of Day')\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Average Speed (km/h)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(range(24))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d34e5a6",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50158049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "train_df, val_df, test_df = split_data(\n",
    "    df_features,\n",
    "    target_column='speed_kmh',\n",
    "    test_size=0.2,\n",
    "    val_size=0.1,\n",
    "    random_state=42,\n",
    "    time_based=False  # Set True for time-series split\n",
    ")\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"  Train: {len(train_df)} samples\")\n",
    "print(f\"  Val:   {len(val_df)} samples\")\n",
    "print(f\"  Test:  {len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb286a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X_train, y_train = prepare_features_target(train_df, target_column='speed_kmh')\n",
    "X_val, y_val = prepare_features_target(val_df, target_column='speed_kmh')\n",
    "X_test, y_test = prepare_features_target(test_df, target_column='speed_kmh')\n",
    "\n",
    "print(f\"\\nFeature matrix shape:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_val:   {X_val.shape}\")\n",
    "print(f\"  X_test:  {X_test.shape}\")\n",
    "\n",
    "print(f\"\\nFeatures used: {list(X_train.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data (scaling, imputation)\n",
    "preprocessor = DataPreprocessor(\n",
    "    target_column='speed_kmh',\n",
    "    scaler_type='standard',  # 'standard', 'robust', or 'none'\n",
    "    handle_outliers=True\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "preprocessor.fit(train_df, feature_columns=list(X_train.columns))\n",
    "\n",
    "# Transform all sets\n",
    "train_processed = preprocessor.transform(train_df)\n",
    "val_processed = preprocessor.transform(val_df)\n",
    "test_processed = preprocessor.transform(test_df)\n",
    "\n",
    "# Extract preprocessed features\n",
    "X_train_scaled, _ = prepare_features_target(train_processed, target_column='speed_kmh')\n",
    "X_val_scaled, _ = prepare_features_target(val_processed, target_column='speed_kmh')\n",
    "X_test_scaled, _ = prepare_features_target(test_processed, target_column='speed_kmh')\n",
    "\n",
    "print(\"‚úÖ Data preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb117d",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e90fd",
   "metadata": {},
   "source": [
    "### 6.1 Train Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c44f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "trainer = ModelTrainer(\n",
    "    model_type='random_forest',\n",
    "    params={\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'min_samples_split': 5,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train(X_train_scaled, y_train, X_val_scaled, y_val)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics = trainer.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0278bd",
   "metadata": {},
   "source": [
    "### 6.2 Compare Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all available models\n",
    "comparison_df = compare_models(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    X_test_scaled,\n",
    "    y_test,\n",
    "    models=['random_forest', 'gradient_boosting', 'xgboost', 'lightgbm', 'ridge']\n",
    ")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "axes[0].bar(comparison_df['model'], comparison_df['rmse'])\n",
    "axes[0].set_title('RMSE Comparison')\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# R¬≤ comparison\n",
    "axes[1].bar(comparison_df['model'], comparison_df['r2'])\n",
    "axes[1].set_title('R¬≤ Comparison')\n",
    "axes[1].set_xlabel('Model')\n",
    "axes[1].set_ylabel('R¬≤')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# MAE comparison\n",
    "axes[2].bar(comparison_df['model'], comparison_df['mae'])\n",
    "axes[2].set_title('MAE Comparison')\n",
    "axes[2].set_xlabel('Model')\n",
    "axes[2].set_ylabel('MAE')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d16682",
   "metadata": {},
   "source": [
    "### 6.3 Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb431ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "cv_results = trainer.cross_validate(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "print(f\"\\nCross-validation scores: {cv_results['scores']}\")\n",
    "print(f\"Mean CV score: {cv_results['mean_score']:.4f} (+/- {cv_results['std_score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da59886",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = trainer.predict(X_test_scaled)\n",
    "\n",
    "# Prediction vs Actual plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test, y_pred, alpha=0.5)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_title('Predicted vs Actual Speed')\n",
    "axes[0].set_xlabel('Actual Speed (km/h)')\n",
    "axes[0].set_ylabel('Predicted Speed (km/h)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals plot\n",
    "residuals = y_test - y_pred\n",
    "axes[1].scatter(y_pred, residuals, alpha=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_title('Residuals Plot')\n",
    "axes[1].set_xlabel('Predicted Speed (km/h)')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Error distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(residuals, bins=50, edgecolor='black')\n",
    "plt.axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "plt.title('Error Distribution')\n",
    "plt.xlabel('Prediction Error (km/h)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17cb098",
   "metadata": {},
   "source": [
    "## 8. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77562d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_df = trainer.get_feature_importance(top_n=20)\n",
    "\n",
    "if not importance_df.empty:\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(importance_df['feature'], importance_df['importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 20 Feature Importance')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(importance_df.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"Feature importance not available for this model type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fa8c0d",
   "metadata": {},
   "source": [
    "## 9. Hyperparameter Tuning (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Tune hyperparameters\n",
    "tuning_trainer = ModelTrainer(model_type='random_forest')\n",
    "tuning_results = tuning_trainer.tune_hyperparameters(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "print(f\"\\nBest parameters: {tuning_results['best_params']}\")\n",
    "print(f\"Best CV score: {tuning_results['best_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3bf936",
   "metadata": {},
   "source": [
    "## 10. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab851108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model_path = trainer.save_model(name='best_traffic_model.joblib')\n",
    "\n",
    "print(f\"\\n‚úÖ Model saved to: {model_path}\")\n",
    "print(f\"\\nModel performance summary:\")\n",
    "print(f\"  Training R¬≤: {trainer.training_metrics['r2']:.4f}\")\n",
    "if trainer.validation_metrics:\n",
    "    print(f\"  Validation R¬≤: {trainer.validation_metrics['r2']:.4f}\")\n",
    "print(f\"  Test R¬≤: {trainer.test_metrics['r2']:.4f}\")\n",
    "print(f\"  Test RMSE: {trainer.test_metrics['rmse']:.4f}\")\n",
    "print(f\"  Test MAE: {trainer.test_metrics['mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3d0bdc",
   "metadata": {},
   "source": [
    "## 11. Load and Use Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961983d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "loaded_trainer = ModelTrainer.load_model(model_path)\n",
    "\n",
    "# Make predictions with loaded model\n",
    "y_pred_loaded = loaded_trainer.predict(X_test_scaled)\n",
    "\n",
    "# Verify predictions match\n",
    "assert np.allclose(y_pred, y_pred_loaded), \"Predictions don't match!\"\n",
    "print(\"‚úÖ Model loaded successfully and predictions verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d14237",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- ‚úÖ Loading traffic data from collected runs\n",
    "- ‚úÖ Exploratory data analysis\n",
    "- ‚úÖ Feature engineering (temporal, spatial, weather)\n",
    "- ‚úÖ Data preprocessing and splitting\n",
    "- ‚úÖ Training multiple ML models\n",
    "- ‚úÖ Model evaluation and comparison\n",
    "- ‚úÖ Feature importance analysis\n",
    "- ‚úÖ Hyperparameter tuning\n",
    "- ‚úÖ Model persistence and loading\n",
    "\n",
    "### Next Steps:\n",
    "1. Collect more data for better model performance\n",
    "2. Try advanced models (neural networks, ensemble methods)\n",
    "3. Implement real-time prediction API\n",
    "4. Deploy model to production\n",
    "5. Monitor model performance over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439ebf89",
   "metadata": {},
   "source": [
    "## 12. Deep Learning Models (LSTM) üß†\n",
    "\n",
    "For time-series forecasting, LSTM models can capture temporal dependencies better than traditional ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b0aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if deep learning is available\n",
    "from traffic_forecast.ml import HAS_DL\n",
    "\n",
    "if HAS_DL:\n",
    "    from traffic_forecast.ml import DLModelTrainer\n",
    "    print(\"‚úì Deep Learning models available\")\n",
    "    print(f\"  Available models: {list(DLModelTrainer.MODELS.keys())}\")\n",
    "else:\n",
    "    print(\"‚úó Deep Learning not available\")\n",
    "    print(\"  Install TensorFlow: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865c0d7",
   "metadata": {},
   "source": [
    "### 12.1 Train LSTM Model\n",
    "\n",
    "LSTM (Long Short-Term Memory) is designed for sequential data and can learn long-term dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_DL:\n",
    "    # Create LSTM trainer\n",
    "    lstm_trainer = DLModelTrainer(\n",
    "        model_type='lstm',\n",
    "        params={\n",
    "            'sequence_length': 12,  # Use last 12 timesteps\n",
    "            'lstm_units': [128, 64],\n",
    "            'dropout_rate': 0.2,\n",
    "            'learning_rate': 0.001\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"Training LSTM model...\")\n",
    "    print(f\"Training samples: {len(X_train_scaled)}\")\n",
    "    print(f\"This may take a few minutes...\")\n",
    "    \n",
    "    # Train (fewer epochs for demo)\n",
    "    lstm_trainer.train(\n",
    "        X_train_scaled, y_train,\n",
    "        X_val_scaled, y_val,\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úì LSTM training complete!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping LSTM training - TensorFlow not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc5c4f",
   "metadata": {},
   "source": [
    "### 12.2 Evaluate LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb9fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_DL and 'lstm_trainer' in locals():\n",
    "    # Evaluate on test set\n",
    "    lstm_metrics = lstm_trainer.evaluate(X_test_scaled, y_test)\n",
    "    \n",
    "    print(\"LSTM Test Metrics:\")\n",
    "    print(f\"  RMSE: {lstm_metrics['rmse']:.4f}\")\n",
    "    print(f\"  MAE:  {lstm_metrics['mae']:.4f}\")\n",
    "    print(f\"  R¬≤:   {lstm_metrics['r2']:.4f}\")\n",
    "    print(f\"  MAPE: {lstm_metrics['mape']:.2f}%\")\n",
    "    \n",
    "    # Compare with best traditional ML model\n",
    "    print(f\"\\nComparison with XGBoost:\")\n",
    "    print(f\"  XGBoost R¬≤: {xgb_metrics['r2']:.4f}\")\n",
    "    print(f\"  LSTM R¬≤:    {lstm_metrics['r2']:.4f}\")\n",
    "    \n",
    "    if lstm_metrics['r2'] > xgb_metrics['r2']:\n",
    "        print(\"  ‚Üí LSTM performs better! üéâ\")\n",
    "    else:\n",
    "        print(\"  ‚Üí XGBoost still better (more data may help LSTM)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è LSTM not trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc47390",
   "metadata": {},
   "source": [
    "### 12.3 Save LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c407cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_DL and 'lstm_trainer' in locals():\n",
    "    # Save LSTM model\n",
    "    lstm_path = lstm_trainer.save_model('traffic_lstm_v1')\n",
    "    print(f\"‚úì LSTM model saved to {lstm_path}\")\n",
    "    \n",
    "    # Model can be loaded later with:\n",
    "    # loaded_lstm = DLModelTrainer.load_model(lstm_path, model_type='lstm')\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è LSTM not trained, nothing to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5793b3d9",
   "metadata": {},
   "source": [
    "## 13. Model Selection Guidance üéØ\n",
    "\n",
    "### When to use each model:\n",
    "\n",
    "| Model | Best For | Speed | Accuracy | Data Needed |\n",
    "|-------|----------|-------|----------|-------------|\n",
    "| **Ridge/Lasso** | Baseline, interpretability | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | Small |\n",
    "| **Random Forest** | General purpose, robust | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Medium |\n",
    "| **XGBoost** | Best accuracy (tabular) | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Medium |\n",
    "| **LightGBM** | Speed + accuracy | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Medium |\n",
    "| **LSTM** | Time series, sequences | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Large |\n",
    "| **ASTGCN** | Graph + time series | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Large + Graph |\n",
    "\n",
    "### Recommendations:\n",
    "- **For production**: Use XGBoost or LightGBM (best balance)\n",
    "- **For research**: Try LSTM with more data\n",
    "- **For real-time**: Use LightGBM (fastest)\n",
    "- **For baseline**: Start with Ridge/Random Forest"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
