{
 "cells": [
 {
 "cell_type": "markdown",
 "id": "58e289d5",
 "metadata": {},
 "source": [
 "# Maintainer Contact\n",
 "\n",
 "**Name:** THAT Le Quang (Xiel)\n",
 "\n",
 "- **Role:** AI & DS Major Student\n",
 "- **GitHub:** [thatlq1812](https://github.com/thatlq1812)\n",
 "- **Email:** fxlqthat@gmail.com / thatlqse183256@fpt.edu.com / thatlq1812@gmail.com\n",
 "- **Phone:** +84 33 863 6369 / +84 39 730 6450\n"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "c2365955",
 "metadata": {},
 "source": [
 "# Traffic Forecast System - Complete Runbook\n",
 "\n",
 "**Version**: Academic v4.0 \n",
 "**Purpose**: Complete setup and operation guide \n",
 "**Last Updated**: October 25, 2025\n",
 "\n",
 "---\n",
 "\n",
 "## Table of Contents\n",
 "\n",
 "1. [Environment Setup](#1-Environment-Setup)\n",
 "2. [Configuration Management](#2-Configuration-Management)\n",
 "3. [Data Collection](#3-Data-Collection)\n",
 "4. [Model Training](#4-Model-Training)\n",
 "5. [Visualization](#5-Visualization)\n",
 "6. [Monitoring](#6-Monitoring)\n",
 "7. [Troubleshooting](#7-Troubleshooting)\n",
 "\n",
 "---\n",
 "\n",
 "## Prerequisites\n",
 "\n",
 "- Python 3.8+\n",
 "- Conda or Miniconda\n",
 "- Internet connection\n",
 "- Google Maps API key (optional - can use mock API)"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "f39155ef",
 "metadata": {},
 "source": [
 "## 1. Environment Setup\n",
 "\n",
 "### 1.1 Install Miniconda (if not installed)\n",
 "\n",
 "**Windows**:"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "e02194ec",
 "metadata": {},
 "outputs": [],
 "source": [
 "# Run in terminal (not this notebook):\n",
 "# Download from: https://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe\n",
 "# Install and restart terminal\n",
 "\n",
 "print(\"For Windows: Download and install Miniconda from https://docs.conda.io/en/latest/miniconda.html\")\n",
 "print(\"Then restart your terminal and continue.\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "059d4ee2",
 "metadata": {},
 "source": [
 "**Linux/Mac**:"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "00f3fd72",
 "metadata": {},
 "outputs": [],
 "source": [
 "%%bash\n",
 "# Run this cell to install Miniconda on Linux/Mac\n",
 "\n",
 "if ! command -v conda &> /dev/null; then\n",
 " echo \"Installing Miniconda...\"\n",
 " wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh\n",
 " bash ~/miniconda.sh -b -p $HOME/miniconda3\n",
 " rm ~/miniconda.sh\n",
 " \n",
 " # Initialize conda\n",
 " $HOME/miniconda3/bin/conda init bash\n",
 " echo \"Miniconda installed! Please restart your terminal.\"\n",
 "else\n",
 " echo \"Conda already installed\"\n",
 " conda --version\n",
 "fi"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "f30c7f71",
 "metadata": {},
 "source": [
 "### 1.2 Create Conda Environment"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "c8d8f1b4",
 "metadata": {},
 "outputs": [],
 "source": [
 "# Check if running in the correct directory\n",
 "import os\n",
 "import sys\n",
 "\n",
 "expected_files = ['environment.yml', 'configs/project_config.yaml', 'README.md']\n",
 "missing_files = [f for f in expected_files if not os.path.exists(f)]\n",
 "\n",
 "if missing_files:\n",
 " print(\"ERROR: Not in project root directory!\")\n",
 " print(f\"Missing files: {missing_files}\")\n",
 " print(f\"Current directory: {os.getcwd()}\")\n",
 " print(\"\\nPlease navigate to project root before running this notebook.\")\n",
 "else:\n",
 " print(\"Project directory: OK\")\n",
 " print(f\"Location: {os.getcwd()}\")\n",
 " print(\"\\nReady to proceed!\")"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "0a4bd25a",
 "metadata": {},
 "outputs": [],
 "source": [
 "%%bash\n",
 "# Create conda environment from environment.yml\n",
 "\n",
 "if conda env list | grep -q \"^dsp \"; then\n",
 " echo \"Environment 'dsp' already exists\"\n",
 " echo \"Updating environment...\"\n",
 " conda env update -f environment.yml -n dsp\n",
 "else\n",
 " echo \"Creating environment 'dsp'...\"\n",
 " conda env create -f environment.yml\n",
 "fi\n",
 "\n",
 "echo \"\"\n",
 "echo \"Environment ready!\"\n",
 "echo \"Activate with: conda activate dsp\""
 ]
 },
 {
 "cell_type": "markdown",
 "id": "1c03e14d",
 "metadata": {},
 "source": [
 "### 1.3 Verify Installation"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "edd694b4",
 "metadata": {},
 "outputs": [],
 "source": [
 "# Verify Python version and key packages\n",
 "import sys\n",
 "print(f\"Python version: {sys.version}\")\n",
 "print()\n",
 "\n",
 "# Test imports\n",
 "packages = [\n",
 " 'yaml',\n",
 " 'pandas',\n",
 " 'numpy',\n",
 " 'requests',\n",
 " 'pydantic',\n",
 " 'sklearn',\n",
 " 'matplotlib',\n",
 " 'seaborn'\n",
 "]\n",
 "\n",
 "print(\"Testing package imports:\")\n",
 "for pkg in packages:\n",
 " try:\n",
 " __import__(pkg)\n",
 " print(f\" {pkg}: OK\")\n",
 " except ImportError as e:\n",
 " print(f\" {pkg}: FAILED - {e}\")\n",
 "\n",
 "print(\"\\nInstallation verification complete!\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "73a28c88",
 "metadata": {},
 "source": [
 "## 2. Configuration Management\n",
 "\n",
 "### 2.1 View Current Configuration"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "095620f0",
 "metadata": {},
 "outputs": [],
 "source": [
 "import yaml\n",
 "from pprint import pprint\n",
 "\n",
 "# Load configuration\n",
 "with open('configs/project_config.yaml', 'r') as f:\n",
 " config = yaml.safe_load(f)\n",
 "\n",
 "print(\"Current Configuration:\")\n",
 "print(\"=\" * 50)\n",
 "print()\n",
 "\n",
 "print(f\"Project: {config['project']['name']} v{config['project']['version']}\")\n",
 "print(f\"Timezone: {config['globals']['timezone']}\")\n",
 "print()\n",
 "\n",
 "print(\"Scheduler:\")\n",
 "print(f\" Mode: {config['scheduler']['mode']}\")\n",
 "print(f\" Enabled: {config['scheduler']['enabled']}\")\n",
 "print()\n",
 "\n",
 "print(\"Node Selection:\")\n",
 "print(f\" Max nodes: {config['node_selection']['max_nodes']}\")\n",
 "print(f\" Min degree: {config['node_selection']['min_degree']}\")\n",
 "print(f\" Min importance: {config['node_selection']['min_importance_score']}\")\n",
 "print()\n",
 "\n",
 "print(\"Google Directions:\")\n",
 "print(f\" Mock API: {config['google_directions']['use_mock_api']}\")\n",
 "print(f\" Radius: {config['google_directions']['radius_km']} km\")\n",
 "print(f\" K neighbors: {config['google_directions']['k_neighbors']}\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "6b5315d4",
 "metadata": {},
 "source": [
 "### 2.2 View Adaptive Schedule"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "41bda0b9",
 "metadata": {},
 "outputs": [],
 "source": [
 "# Display peak hours\n",
 "peak_hours = config['scheduler']['adaptive']['peak_hours']['time_ranges']\n",
 "\n",
 "print(\"Vietnam Peak Hours:\")\n",
 "print(\"=\" * 50)\n",
 "for i, range_info in enumerate(peak_hours, 1):\n",
 " print(f\"{i}. {range_info['start']} - {range_info['end']}\")\n",
 "\n",
 "print()\n",
 "print(\"Collection Intervals:\")\n",
 "print(f\" Peak: {config['scheduler']['adaptive']['peak_interval_minutes']} minutes\")\n",
 "print(f\" Off-peak: {config['scheduler']['adaptive']['offpeak_interval_minutes']} minutes\")\n",
 "print(f\" Weekend: {config['scheduler']['adaptive']['weekend_interval_minutes']} minutes\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "6d6eb888",
 "metadata": {},
 "source": [
 "### 2.3 Modify Configuration (Optional)"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "a7d2299a",
 "metadata": {},
 "outputs": [],
 "source": [
 "# Example: Switch between mock and real API\n",
 "\n",
 "def toggle_mock_api(enable_mock=True):\n",
 " \"\"\"\n",
 " Toggle between mock API (free) and real Google API\n",
 " \n",
 " Args:\n",
 " enable_mock: True for mock API (free), False for real API\n",
 " \"\"\"\n",
 " with open('configs/project_config.yaml', 'r') as f:\n",
 " config = yaml.safe_load(f)\n",
 " \n",
 " config['google_directions']['use_mock_api'] = enable_mock\n",
 " \n",
 " with open('configs/project_config.yaml', 'w') as f:\n",
 " yaml.dump(config, f, default_flow_style=False)\n",
 " \n",
 " mode = \"MOCK (free)\" if enable_mock else \"REAL (costs money)\"\n",
 " print(f\"API mode set to: {mode}\")\n",
 " \n",
 " if not enable_mock:\n",
 " print(\"\\nWARNING: Using real Google API!\")\n",
 " print(\"Make sure GOOGLE_MAPS_API_KEY is set in .env\")\n",
 " print(\"Estimated cost: $720/month for current configuration\")\n",
 "\n",
 "# Uncomment to use:\n",
 "# toggle_mock_api(enable_mock=True) # Use mock API (free)\n",
 "# toggle_mock_api(enable_mock=False) # Use real API (costs money)\n",
 "\n",
 "print(\"Function defined. Uncomment lines above to use.\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "cdb5dafe",
 "metadata": {},
 "source": [
 "## 3. Data Collection\n",
 "\n",
 "### 3.1 Single Collection Run"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "4876b7ea",
 "metadata": {},
 "outputs": [],
 "source": [
 "%%bash\n",
 "# Run one collection cycle\n",
 "# This will collect traffic, weather, and node features\n",
 "\n",
 "python scripts/collect_and_render.py --once --no-visualize"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "54726513",
 "metadata": {},
 "source": [
 "### 3.2 View Collected Data"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "376c9478",
 "metadata": {},
 "outputs": [],
 "source": [
 "import pandas as pd\n",
 "import json\n",
 "from datetime import datetime\n",
 "\n",
 "# Load latest traffic snapshot\n",
 "try:\n",
 " with open('data/traffic_snapshot_normalized.json', 'r') as f:\n",
 " traffic_data = json.load(f)\n",
 " \n",
 " df = pd.DataFrame(traffic_data)\n",
 " \n",
 " print(\"Latest Traffic Snapshot:\")\n",
 " print(\"=\" * 50)\n",
 " print(f\"Records: {len(df)}\")\n",
 " print(f\"Timestamp: {df['timestamp'].iloc[0] if len(df) > 0 else 'N/A'}\")\n",
 " print()\n",
 " \n",
 " print(\"Sample data:\")\n",
 " display(df.head())\n",
 " \n",
 " print(\"\\nTraffic Level Distribution:\")\n",
 " print(df['traffic_level'].value_counts())\n",
 " \n",
 "except FileNotFoundError:\n",
 " print(\"No traffic data found. Run a collection first.\")\n",
 "except Exception as e:\n",
 " print(f\"Error loading data: {e}\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "ef3ce014",
 "metadata": {},
 "source": [
 "### 3.3 Check Collection Schedule"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "93262ab1",
 "metadata": {},
 "outputs": [],
 "source": [
 "%%bash\n",
 "# Display collection schedule\n",
 "python scripts/collect_and_render.py --print-schedule"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "c9a7dbf4",
 "metadata": {},
 "source": [
 "### 3.4 Start Continuous Collection (Background)\n",
 "\n",
 "**Note**: This will start a background process. Use with caution in notebooks."
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "a7897fe3",
 "metadata": {},
 "outputs": [],
 "source": [
 "import subprocess\n",
 "import os\n",
 "\n",
 "# Only uncomment if you want to start background collection\n",
 "# WARNING: This will run continuously until stopped\n",
 "\n",
 "# proc = subprocess.Popen(\n",
 "# ['python', 'scripts/collect_and_render.py', '--adaptive'],\n",
 "# stdout=subprocess.PIPE,\n",
 "# stderr=subprocess.PIPE,\n",
 "# text=True\n",
 "# )\n",
 "# print(f\"Collection started with PID: {proc.pid}\")\n",
 "# print(\"To stop: kill the process or restart the kernel\")\n",
 "\n",
 "print(\"Background collection disabled in notebook.\")\n",
 "print(\"For production, use:\")\n",
 "print(\" bash scripts/start_collection.sh\")\n",
 "print(\"or:\")\n",
 "print(\" sudo systemctl start traffic-forecast.service\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "58cca5e9",
 "metadata": {},
 "source": [
 "## 4. Model Training\n",
 "\n",
 "### 4.1 Load Training Data"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "fa11ff16",
 "metadata": {},
 "outputs": [],
 "source": [
 "# Check for training data\n",
 "import os\n",
 "import pandas as pd\n",
 "\n",
 "data_dir = 'data/processed'\n",
 "\n",
 "if os.path.exists(f\"{data_dir}/val_predictions.csv\"):\n",
 " df_val = pd.read_csv(f\"{data_dir}/val_predictions.csv\")\n",
 " print(\"Validation Predictions:\")\n",
 " print(\"=\" * 50)\n",
 " print(f\"Records: {len(df_val)}\")\n",
 " display(df_val.head())\n",
 " \n",
 " # Calculate accuracy\n",
 " if 'actual' in df_val.columns and 'predicted' in df_val.columns:\n",
 " accuracy = (df_val['actual'] == df_val['predicted']).mean()\n",
 " print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
 "else:\n",
 " print(\"No training data found.\")\n",
 " print(\"Run the training pipeline first.\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "04c65559",
 "metadata": {},
 "source": [
 "### 4.2 View Model Performance"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "f4ef0d02",
 "metadata": {},
 "outputs": [],
 "source": [
 "# Load model metadata\n",
 "import json\n",
 "\n",
 "try:\n",
 " with open('models/model_metadata.json', 'r') as f:\n",
 " metadata = json.load(f)\n",
 " \n",
 " print(\"Model Information:\")\n",
 " print(\"=\" * 50)\n",
 " print(json.dumps(metadata, indent=2))\n",
 " \n",
 "except FileNotFoundError:\n",
 " print(\"No model metadata found.\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "e27b6794",
 "metadata": {},
 "source": [
 "## 5. Visualization\n",
 "\n",
 "### 5.1 Traffic Level Distribution"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "8bf4e796",
 "metadata": {},
 "outputs": [],
 "source": [
 "import matplotlib.pyplot as plt\n",
 "import seaborn as sns\n",
 "\n",
 "# Set style\n",
 "sns.set_style(\"whitegrid\")\n",
 "plt.rcParams['figure.figsize'] = (12, 6)\n",
 "\n",
 "# Load data\n",
 "try:\n",
 " with open('data/traffic_snapshot_normalized.json', 'r') as f:\n",
 " traffic_data = json.load(f)\n",
 " df = pd.DataFrame(traffic_data)\n",
 " \n",
 " # Plot traffic levels\n",
 " plt.figure(figsize=(10, 6))\n",
 " df['traffic_level'].value_counts().sort_index().plot(kind='bar', color='steelblue')\n",
 " plt.title('Traffic Level Distribution', fontsize=14, fontweight='bold')\n",
 " plt.xlabel('Traffic Level', fontsize=12)\n",
 " plt.ylabel('Count', fontsize=12)\n",
 " plt.xticks(rotation=0)\n",
 " plt.tight_layout()\n",
 " plt.show()\n",
 " \n",
 "except FileNotFoundError:\n",
 " print(\"No data available for visualization\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "f11f2fda",
 "metadata": {},
 "source": [
 "### 5.2 Duration Analysis"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "ae1396ad",
 "metadata": {},
 "outputs": [],
 "source": [
 "# Duration distribution\n",
 "if 'df' in locals():\n",
 " plt.figure(figsize=(12, 6))\n",
 " \n",
 " plt.subplot(1, 2, 1)\n",
 " plt.hist(df['duration_seconds'], bins=30, color='coral', edgecolor='black')\n",
 " plt.title('Duration Distribution', fontsize=12, fontweight='bold')\n",
 " plt.xlabel('Duration (seconds)', fontsize=10)\n",
 " plt.ylabel('Frequency', fontsize=10)\n",
 " \n",
 " plt.subplot(1, 2, 2)\n",
 " df.boxplot(column='duration_seconds', by='traffic_level')\n",
 " plt.title('Duration by Traffic Level', fontsize=12, fontweight='bold')\n",
 " plt.suptitle('') # Remove automatic title\n",
 " plt.xlabel('Traffic Level', fontsize=10)\n",
 " plt.ylabel('Duration (seconds)', fontsize=10)\n",
 " \n",
 " plt.tight_layout()\n",
 " plt.show()\n",
 "else:\n",
 " print(\"Load data first\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "68ad6fa0",
 "metadata": {},
 "source": [
 "## 6. Monitoring\n",
 "\n",
 "### 6.1 Check System Status"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "3d9c185e",
 "metadata": {},
 "outputs": [],
 "source": [
 "import os\n",
 "import subprocess\n",
 "from datetime import datetime\n",
 "\n",
 "print(\"System Status\")\n",
 "print(\"=\" * 50)\n",
 "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
 "print()\n",
 "\n",
 "# Check disk usage\n",
 "def get_dir_size(path):\n",
 " total = 0\n",
 " for dirpath, dirnames, filenames in os.walk(path):\n",
 " for f in filenames:\n",
 " fp = os.path.join(dirpath, f)\n",
 " if os.path.exists(fp):\n",
 " total += os.path.getsize(fp)\n",
 " return total / (1024 * 1024) # MB\n",
 "\n",
 "print(\"Storage Usage:\")\n",
 "if os.path.exists('data'):\n",
 " print(f\" data/: {get_dir_size('data'):.2f} MB\")\n",
 "if os.path.exists('cache'):\n",
 " print(f\" cache/: {get_dir_size('cache'):.2f} MB\")\n",
 "if os.path.exists('logs'):\n",
 " print(f\" logs/: {get_dir_size('logs'):.2f} MB\")\n",
 "if os.path.exists('traffic_history.db'):\n",
 " print(f\" database: {os.path.getsize('traffic_history.db') / (1024*1024):.2f} MB\")\n",
 "\n",
 "print()\n",
 "\n",
 "# Count data runs\n",
 "if os.path.exists('data/node'):\n",
 " runs = [d for d in os.listdir('data/node') if os.path.isdir(os.path.join('data/node', d))]\n",
 " print(f\"Data runs: {len(runs)}\")\n",
 " if runs:\n",
 " print(f\"Latest: {max(runs)}\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "d2428484",
 "metadata": {},
 "source": [
 "### 6.2 View Recent Logs"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "ce8d77fe",
 "metadata": {},
 "outputs": [],
 "source": [
 "# View last 20 lines of log\n",
 "import os\n",
 "\n",
 "log_file = 'logs/service.log'\n",
 "if os.path.exists(log_file):\n",
 " with open(log_file, 'r') as f:\n",
 " lines = f.readlines()\n",
 " print(\"Recent Logs (last 20 lines):\")\n",
 " print(\"=\" * 50)\n",
 " print(''.join(lines[-20:]))\n",
 "else:\n",
 " print(\"No log file found\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "5e49039a",
 "metadata": {},
 "source": [
 "### 6.3 Database Query"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "cb7ab2f0",
 "metadata": {},
 "outputs": [],
 "source": [
 "import sqlite3\n",
 "import pandas as pd\n",
 "\n",
 "db_path = 'traffic_history.db'\n",
 "\n",
 "if os.path.exists(db_path):\n",
 " conn = sqlite3.connect(db_path)\n",
 " \n",
 " # Get table info\n",
 " tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table'\", conn)\n",
 " print(\"Database Tables:\")\n",
 " print(tables)\n",
 " print()\n",
 " \n",
 " # Query traffic history\n",
 " try:\n",
 " query = \"\"\"\n",
 " SELECT * FROM traffic_history \n",
 " ORDER BY timestamp DESC \n",
 " LIMIT 10\n",
 " \"\"\"\n",
 " df_history = pd.read_sql(query, conn)\n",
 " print(\"Recent Traffic History:\")\n",
 " display(df_history)\n",
 " \n",
 " # Statistics\n",
 " count_query = \"SELECT COUNT(*) as total FROM traffic_history\"\n",
 " total = pd.read_sql(count_query, conn)['total'].iloc[0]\n",
 " print(f\"\\nTotal records: {total}\")\n",
 " \n",
 " except Exception as e:\n",
 " print(f\"Error querying database: {e}\")\n",
 " \n",
 " conn.close()\n",
 "else:\n",
 " print(\"Database not found. Run collection with history enabled.\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "2ae14aa8",
 "metadata": {},
 "source": [
 "## 7. Troubleshooting\n",
 "\n",
 "### 7.1 Common Issues\n",
 "\n",
 "#### Import Errors"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "d679f802",
 "metadata": {},
 "outputs": [],
 "source": [
 "# Reinstall packages\n",
 "%%bash\n",
 "pip install -r requirements.txt --upgrade"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "c21431c5",
 "metadata": {},
 "source": [
 "#### Permission Errors"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "5fa00596",
 "metadata": {},
 "outputs": [],
 "source": [
 "%%bash\n",
 "# Fix script permissions\n",
 "chmod +x scripts/*.sh\n",
 "chmod 755 scripts/*.py\n",
 "echo \"Permissions fixed\""
 ]
 },
 {
 "cell_type": "markdown",
 "id": "d5928838",
 "metadata": {},
 "source": [
 "### 7.2 System Cleanup"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "ca03d934",
 "metadata": {},
 "outputs": [],
 "source": [
 "%%bash\n",
 "# Run cleanup script\n",
 "bash scripts/cleanup.sh"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "b2c05a33",
 "metadata": {},
 "source": [
 "### 7.3 Reset Configuration"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "id": "6718c4e5",
 "metadata": {},
 "outputs": [],
 "source": [
 "# Backup and reset config to defaults\n",
 "import shutil\n",
 "from datetime import datetime\n",
 "\n",
 "config_file = 'configs/project_config.yaml'\n",
 "backup_file = f'configs/project_config.backup.{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.yaml'\n",
 "\n",
 "# Create backup\n",
 "shutil.copy(config_file, backup_file)\n",
 "print(f\"Configuration backed up to: {backup_file}\")\n",
 "print(\"\\nTo restore defaults, copy from configs/project_config_template.yaml\")\n",
 "print(\"(if template exists)\")"
 ]
 },
 {
 "cell_type": "markdown",
 "id": "0d904415",
 "metadata": {},
 "source": [
 "---\n",
 "\n",
 "## Quick Reference\n",
 "\n",
 "### Important Commands\n",
 "\n",
 "```bash\n",
 "# Activate environment\n",
 "conda activate dsp\n",
 "\n",
 "# Single collection\n",
 "python scripts/collect_and_render.py --once\n",
 "\n",
 "# Start continuous collection\n",
 "bash scripts/start_collection.sh\n",
 "\n",
 "# Check schedule\n",
 "python scripts/collect_and_render.py --print-schedule\n",
 "\n",
 "# Cleanup\n",
 "bash scripts/cleanup.sh\n",
 "\n",
 "# View logs\n",
 "tail -f logs/service.log\n",
 "```\n",
 "\n",
 "### Configuration Files\n",
 "\n",
 "- **Main config**: `configs/project_config.yaml`\n",
 "- **Environment**: `.env`\n",
 "- **Schema**: `configs/nodes_schema_v2.json`\n",
 "\n",
 "### Data Locations\n",
 "\n",
 "- **Raw data**: `data/node/`\n",
 "- **Processed**: `data/processed/`\n",
 "- **Database**: `traffic_history.db`\n",
 "- **Models**: `models/`\n",
 "\n",
 "### Documentation\n",
 "\n",
 "- **Deployment**: `DEPLOY.md`\n",
 "- **Reference**: `doc/reference/`\n",
 "- **API Docs**: `doc/reference/GOOGLE_API_COST_ANALYSIS.md`\n",
 "\n",
 "---\n",
 "\n",
 "**Last Updated**: October 25, 2025 \n",
 "**Version**: Academic v4.0"
 ]
 }
 ],
 "metadata": {
 "language_info": {
 "name": "python"
 }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
